# main.py
import asyncio
import json
import logging
from pathlib import Path

# Gi·∫£ s·ª≠ c√°c module ·ªü ƒë√∫ng v·ªã tr√≠
from rag.parser.pdf_parser import PDFParser
from rag.chunking.chunker import Chunker
from core.embedding import EmbeddingModel
from rag.dataclasses import ParsedContent


# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def main():
    # === 1. ƒê∆∞·ªùng d·∫´n file ===
    pdf_path = "diabetes.pdf"
    output_json = "output_chunks.json"

    if not Path(pdf_path).exists():
        logger.error(f"File kh√¥ng t·ªìn t·∫°i: {pdf_path}")
        return

    logger.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {pdf_path}")

    try:
        # === 2. Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn ===
        parser = PDFParser()
        embedding_model = await EmbeddingModel.get_instance()

        chunker = Chunker(
            embedding_model=embedding_model,
            max_tokens=512,
            min_tokens=100,
            overlap_tokens=64,
            similarity_threshold=0.6
        )

        logger.info("üîÑ ƒêang parse PDF...")
        parsed_content = await parser.parse_async(pdf_path)

        logger.info(f"‚úÖ Parse th√†nh c√¥ng: {parsed_content.metadata['num_pages']} trang, {len(parsed_content.tables)} b·∫£ng")

        logger.info("‚úÇÔ∏è  ƒêang chia nh·ªè vƒÉn b·∫£n theo ng·ªØ nghƒ©a...")
        chunks = await chunker.chunk_async(parsed_content)

        logger.info(f"‚úÖ T·∫°o ƒë∆∞·ª£c {len(chunks)} chunk")

        # === 5. (T√πy ch·ªçn) T·∫°o embedding cho t·ª´ng chunk ===
        # N·∫øu b·∫°n mu·ªën l∆∞u lu√¥n embedding
        generate_embeddings = False  # ƒê·∫∑t True n·∫øu mu·ªën
        chunk_dicts = []

        for i, chunk in enumerate(chunks):
            chunk_data = {
                "chunk_index": chunk.metadata.chunk_index,
                "content": chunk.content,
                "word_count": chunk.metadata.word_count,
                "chunking_strategy": chunk.metadata.chunking_strategy
            }

            if generate_embeddings:
                try:
                    emb = await embedding_model.embed(chunk.content)
                    chunk_data["embedding"] = emb
                except Exception as e:
                    logger.warning(f"Embedding failed for chunk {i}: {e}")
                    chunk_data["embedding"] = None

            chunk_dicts.append(chunk_data)

        # === 6. Metadata t·ªïng h·ª£p ===
        result = {
            "source_file": parsed_content.file_path,
            "file_type": parsed_content.file_type,
            "metadata": parsed_content.metadata,
            "tables_extracted": len(parsed_content.tables),
            "total_chunks": len(chunk_dicts),
            "chunks": chunk_dicts
        }

        # === 7. L∆∞u ra file JSON ===
        with open(output_json, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        logger.info(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_json}")

        # === 8. In th·ª≠ 2 chunk ƒë·∫ßu ===
        print("\n--- V√≠ d·ª• chunk ƒë·∫ßu ti√™n ---")
        if chunks:
            print(chunks[0].content[:500] + ("..." if len(chunks[0].content) > 500 else ""))
        else:
            print("(Kh√¥ng c√≥ chunk n√†o)")

    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω: {str(e)}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())